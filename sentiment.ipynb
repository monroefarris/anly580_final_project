{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook leverages several pre-trained sentiment and emotion models to better understand the underlying tone of the political tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages \n",
    "import pandas as pd \n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>user_mention_ids</th>\n",
       "      <th>user_mention_screen_names</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>in_reply_to_screen_name</th>\n",
       "      <th>...</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_friends_count</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>user_favourites_count</th>\n",
       "      <th>user_verfied</th>\n",
       "      <th>user_statuses_count</th>\n",
       "      <th>topic_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-18 00:00:00</td>\n",
       "      <td>Sharp words on guns in Shane Hazel to Stacey A...</td>\n",
       "      <td>['gagovdebate']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>25282846</td>\n",
       "      <td>SimonesNews</td>\n",
       "      <td>Simone Sebastian</td>\n",
       "      <td>Washington DC</td>\n",
       "      <td>3110</td>\n",
       "      <td>5830</td>\n",
       "      <td>1445</td>\n",
       "      <td>True</td>\n",
       "      <td>4400</td>\n",
       "      <td>abrams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-10-18 00:00:01</td>\n",
       "      <td>Stacey Abrams won tonight. She kept to the fac...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1312393604439183361</td>\n",
       "      <td>nching0</td>\n",
       "      <td>Thee Lost Edges of Candace ðŸª¥</td>\n",
       "      <td>34.2073Â° N, 84.1402Â° W</td>\n",
       "      <td>922</td>\n",
       "      <td>752</td>\n",
       "      <td>101529</td>\n",
       "      <td>False</td>\n",
       "      <td>61963</td>\n",
       "      <td>abrams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           created_at  \\\n",
       "0           0  2022-10-18 00:00:00   \n",
       "1           1  2022-10-18 00:00:01   \n",
       "\n",
       "                                                text         hashtags  \\\n",
       "0  Sharp words on guns in Shane Hazel to Stacey A...  ['gagovdebate']   \n",
       "1  Stacey Abrams won tonight. She kept to the fac...               []   \n",
       "\n",
       "  user_mention_ids user_mention_screen_names  retweet_count  favorite_count  \\\n",
       "0               []                        []              5              24   \n",
       "1               []                        []              0               6   \n",
       "\n",
       "   in_reply_to_user_id in_reply_to_screen_name  ...              user_id  \\\n",
       "0                  NaN                     NaN  ...             25282846   \n",
       "1                  NaN                     NaN  ...  1312393604439183361   \n",
       "\n",
       "  user_screen_name                     user_name           user_location  \\\n",
       "0      SimonesNews              Simone Sebastian           Washington DC   \n",
       "1          nching0  Thee Lost Edges of Candace ðŸª¥  34.2073Â° N, 84.1402Â° W   \n",
       "\n",
       "  user_friends_count user_followers_count  user_favourites_count  \\\n",
       "0               3110                 5830                   1445   \n",
       "1                922                  752                 101529   \n",
       "\n",
       "   user_verfied  user_statuses_count  topic_y  \n",
       "0          True                 4400   abrams  \n",
       "1         False                61963   abrams  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in data \n",
    "data = pd.read_csv('./Data/all_data.csv')\n",
    "\n",
    "# Understand output of data\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Data Quality Checks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows with No Text Data: 0\n"
     ]
    }
   ],
   "source": [
    "# Check if there are any rows where with no text data\n",
    "print('Number of Rows with No Text Data:', data['text'].isnull().values.any().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tweets: 51336\n"
     ]
    }
   ],
   "source": [
    "# Get number of Tweets in our corpus \n",
    "print('Number of Tweets:', len(data['text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the basic data quality check we see that every Tweet returned does contain text. With this information, we can now move onto the text cleaning and pre-processing stages. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now clean the text by removing excess punctuation, spaces, and special characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex statement for cleaning \n",
    "replace = [\n",
    "    (r\"(?<=\\d),(?=\\d)\", \"\"),        # Remove commas in numbers\n",
    "    (r\"\\d+\", \"number\"),             # Map digits to special token <numbr>\n",
    "    (r\"[\\t\\n\\r\\*\\.\\@\\,\\-\\/]\", \" \"), # Punctuation and other junk\n",
    "    (r\"\\s+\", \" \")                   # Stips extra whitespace\n",
    "]\n",
    "\n",
    "# looping through all Tweets and applying regex cleaning \n",
    "train_sentences = []\n",
    "for i, d in enumerate(data['text']):\n",
    "    for repl in replace:\n",
    "        d = re.sub(repl[0], repl[1], d)\n",
    "    train_sentences.append(d)\n",
    "\n",
    "# writing output of regex cleaning to df column \n",
    "data['cleaned_text'] = train_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>user_mention_ids</th>\n",
       "      <th>user_mention_screen_names</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>in_reply_to_screen_name</th>\n",
       "      <th>...</th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_friends_count</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>user_favourites_count</th>\n",
       "      <th>user_verfied</th>\n",
       "      <th>user_statuses_count</th>\n",
       "      <th>topic_y</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-18 00:00:00</td>\n",
       "      <td>Sharp words on guns in Shane Hazel to Stacey A...</td>\n",
       "      <td>['gagovdebate']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>SimonesNews</td>\n",
       "      <td>Simone Sebastian</td>\n",
       "      <td>Washington DC</td>\n",
       "      <td>3110</td>\n",
       "      <td>5830</td>\n",
       "      <td>1445</td>\n",
       "      <td>True</td>\n",
       "      <td>4400</td>\n",
       "      <td>abrams</td>\n",
       "      <td>Sharp words on guns in Shane Hazel to Stacey A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-10-18 00:00:01</td>\n",
       "      <td>Stacey Abrams won tonight. She kept to the fac...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>nching0</td>\n",
       "      <td>Thee Lost Edges of Candace ðŸª¥</td>\n",
       "      <td>34.2073Â° N, 84.1402Â° W</td>\n",
       "      <td>922</td>\n",
       "      <td>752</td>\n",
       "      <td>101529</td>\n",
       "      <td>False</td>\n",
       "      <td>61963</td>\n",
       "      <td>abrams</td>\n",
       "      <td>Stacey Abrams won tonight She kept to the fact...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           created_at  \\\n",
       "0           0  2022-10-18 00:00:00   \n",
       "1           1  2022-10-18 00:00:01   \n",
       "\n",
       "                                                text         hashtags  \\\n",
       "0  Sharp words on guns in Shane Hazel to Stacey A...  ['gagovdebate']   \n",
       "1  Stacey Abrams won tonight. She kept to the fac...               []   \n",
       "\n",
       "  user_mention_ids user_mention_screen_names  retweet_count  favorite_count  \\\n",
       "0               []                        []              5              24   \n",
       "1               []                        []              0               6   \n",
       "\n",
       "   in_reply_to_user_id in_reply_to_screen_name  ... user_screen_name  \\\n",
       "0                  NaN                     NaN  ...      SimonesNews   \n",
       "1                  NaN                     NaN  ...          nching0   \n",
       "\n",
       "                      user_name           user_location user_friends_count  \\\n",
       "0              Simone Sebastian           Washington DC               3110   \n",
       "1  Thee Lost Edges of Candace ðŸª¥  34.2073Â° N, 84.1402Â° W                922   \n",
       "\n",
       "  user_followers_count user_favourites_count  user_verfied  \\\n",
       "0                 5830                  1445          True   \n",
       "1                  752                101529         False   \n",
       "\n",
       "   user_statuses_count  topic_y  \\\n",
       "0                 4400   abrams   \n",
       "1                61963   abrams   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  Sharp words on guns in Shane Hazel to Stacey A...  \n",
       "1  Stacey Abrams won tonight She kept to the fact...  \n",
       "\n",
       "[2 rows x 23 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a data frame with a new column `cleaned_text` that contains the cleaned version of each Tweet. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Cleaned Tweets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VADER Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading in sentiment libraries \n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading VADER sentiment model \n",
    "vader_sentiment = SentimentIntensityAnalyzer()\n",
    "\n",
    "# function that returns sentiment score for a series of text \n",
    "def vader_sentiment_scores(text):\n",
    "  score = vader_sentiment.polarity_scores(text)\n",
    "  \n",
    "  return score['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that bins sentiment into positive, negative, and neutral categories based on sentiment score \n",
    "def format_output(row):\n",
    "  polarity = \"neutral\"\n",
    "  if(row>= 0.05):\n",
    "    polarity = \"positive\"\n",
    "  elif(row<= -0.05):\n",
    "    polarity = \"negative\"\n",
    "\n",
    "  return polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting sentiment scores for corpus of text \n",
    "data['sentiment_score'] = data['text'].apply(vader_sentiment_scores)\n",
    "\n",
    "# getting sentiment bins for our data \n",
    "data['sentiment_bin'] = data['sentiment_score'].apply(format_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>user_mention_ids</th>\n",
       "      <th>user_mention_screen_names</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>in_reply_to_screen_name</th>\n",
       "      <th>...</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_friends_count</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>user_favourites_count</th>\n",
       "      <th>user_verfied</th>\n",
       "      <th>user_statuses_count</th>\n",
       "      <th>topic_y</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>sentiment_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-18 00:00:00</td>\n",
       "      <td>Sharp words on guns in Shane Hazel to Stacey A...</td>\n",
       "      <td>['gagovdebate']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Washington DC</td>\n",
       "      <td>3110</td>\n",
       "      <td>5830</td>\n",
       "      <td>1445</td>\n",
       "      <td>True</td>\n",
       "      <td>4400</td>\n",
       "      <td>abrams</td>\n",
       "      <td>Sharp words on guns in Shane Hazel to Stacey A...</td>\n",
       "      <td>0.3818</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-10-18 00:00:01</td>\n",
       "      <td>Stacey Abrams won tonight. She kept to the fac...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>34.2073Â° N, 84.1402Â° W</td>\n",
       "      <td>922</td>\n",
       "      <td>752</td>\n",
       "      <td>101529</td>\n",
       "      <td>False</td>\n",
       "      <td>61963</td>\n",
       "      <td>abrams</td>\n",
       "      <td>Stacey Abrams won tonight She kept to the fact...</td>\n",
       "      <td>0.7351</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-10-18 00:00:01</td>\n",
       "      <td>Why did Joe Rogan send his little brother, Sha...</td>\n",
       "      <td>['GAGovDebate']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>17762</td>\n",
       "      <td>25727</td>\n",
       "      <td>82402</td>\n",
       "      <td>False</td>\n",
       "      <td>43808</td>\n",
       "      <td>abrams</td>\n",
       "      <td>Why did Joe Rogan send his little brother Shan...</td>\n",
       "      <td>-0.2500</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           created_at  \\\n",
       "0           0  2022-10-18 00:00:00   \n",
       "1           1  2022-10-18 00:00:01   \n",
       "2           2  2022-10-18 00:00:01   \n",
       "\n",
       "                                                text         hashtags  \\\n",
       "0  Sharp words on guns in Shane Hazel to Stacey A...  ['gagovdebate']   \n",
       "1  Stacey Abrams won tonight. She kept to the fac...               []   \n",
       "2  Why did Joe Rogan send his little brother, Sha...  ['GAGovDebate']   \n",
       "\n",
       "  user_mention_ids user_mention_screen_names  retweet_count  favorite_count  \\\n",
       "0               []                        []              5              24   \n",
       "1               []                        []              0               6   \n",
       "2               []                        []              0               5   \n",
       "\n",
       "   in_reply_to_user_id in_reply_to_screen_name  ...           user_location  \\\n",
       "0                  NaN                     NaN  ...           Washington DC   \n",
       "1                  NaN                     NaN  ...  34.2073Â° N, 84.1402Â° W   \n",
       "2                  NaN                     NaN  ...                 Seattle   \n",
       "\n",
       "  user_friends_count  user_followers_count user_favourites_count user_verfied  \\\n",
       "0               3110                  5830                  1445         True   \n",
       "1                922                   752                101529        False   \n",
       "2              17762                 25727                 82402        False   \n",
       "\n",
       "  user_statuses_count  topic_y  \\\n",
       "0                4400   abrams   \n",
       "1               61963   abrams   \n",
       "2               43808   abrams   \n",
       "\n",
       "                                        cleaned_text  sentiment_score  \\\n",
       "0  Sharp words on guns in Shane Hazel to Stacey A...           0.3818   \n",
       "1  Stacey Abrams won tonight She kept to the fact...           0.7351   \n",
       "2  Why did Joe Rogan send his little brother Shan...          -0.2500   \n",
       "\n",
       "   sentiment_bin  \n",
       "0       positive  \n",
       "1       positive  \n",
       "2       negative  \n",
       "\n",
       "[3 rows x 25 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examining data frame with sentiment scores and bins\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pysentimiento Sentiment and Emotion Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pysentimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making model instances for each pysentimiento model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9fc2a75579842f0b0e98086108986bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/890 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd22df6400e9476a88fc1ba6c95ad5a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/540M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20bc9498991e4c1fa98f78451df3e24d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/295 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c2f61ae4a8d4be3924b31258686ac8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/843k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ce0ea01ce3e4d39b2401b1b771ca35b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62a66773a11345aa832f16ca1e007364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/17.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c08a58ff4beb4c719cb12fd696b8ca3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d4cdb53bb534e86bac236d6069a100e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/999 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /Users/sampastoriza/.cache/huggingface/hub/models--finiteautomata--bertweet-base-emotion-analysis/snapshots/64046df9cc41eab40e1ecde7d2b7fb42b971be5b/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"finiteautomata/bertweet-base-emotion-analysis\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"others\",\n",
      "    \"1\": \"joy\",\n",
      "    \"2\": \"sadness\",\n",
      "    \"3\": \"anger\",\n",
      "    \"4\": \"surprise\",\n",
      "    \"5\": \"disgust\",\n",
      "    \"6\": \"fear\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 3,\n",
      "    \"disgust\": 5,\n",
      "    \"fear\": 6,\n",
      "    \"joy\": 1,\n",
      "    \"others\": 0,\n",
      "    \"sadness\": 2,\n",
      "    \"surprise\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"tokenizer_class\": \"BertweetTokenizer\",\n",
      "  \"transformers_version\": \"4.23.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 64001\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e071e1dde15c44ee98207f6e474b8c89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/540M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file pytorch_model.bin from cache at /Users/sampastoriza/.cache/huggingface/hub/models--finiteautomata--bertweet-base-emotion-analysis/snapshots/64046df9cc41eab40e1ecde7d2b7fb42b971be5b/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at finiteautomata/bertweet-base-emotion-analysis.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59a57cc3af8646e7bf4479d794877a26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/295 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /Users/sampastoriza/.cache/huggingface/hub/models--finiteautomata--bertweet-base-emotion-analysis/snapshots/64046df9cc41eab40e1ecde7d2b7fb42b971be5b/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"finiteautomata/bertweet-base-emotion-analysis\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"others\",\n",
      "    \"1\": \"joy\",\n",
      "    \"2\": \"sadness\",\n",
      "    \"3\": \"anger\",\n",
      "    \"4\": \"surprise\",\n",
      "    \"5\": \"disgust\",\n",
      "    \"6\": \"fear\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 3,\n",
      "    \"disgust\": 5,\n",
      "    \"fear\": 6,\n",
      "    \"joy\": 1,\n",
      "    \"others\": 0,\n",
      "    \"sadness\": 2,\n",
      "    \"surprise\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"tokenizer_class\": \"BertweetTokenizer\",\n",
      "  \"transformers_version\": \"4.23.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 64001\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f2bdff2a2fc427d855f452970e859b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/843k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "372c27173bd444e1a2b7b0ae7e02c40d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd5a5f35c0c543f5a9fbb178b3bf4ed9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/17.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1401a98dc594ee9bf28cb4d75eb5f8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.txt from cache at /Users/sampastoriza/.cache/huggingface/hub/models--finiteautomata--bertweet-base-emotion-analysis/snapshots/64046df9cc41eab40e1ecde7d2b7fb42b971be5b/vocab.txt\n",
      "loading file bpe.codes from cache at /Users/sampastoriza/.cache/huggingface/hub/models--finiteautomata--bertweet-base-emotion-analysis/snapshots/64046df9cc41eab40e1ecde7d2b7fb42b971be5b/bpe.codes\n",
      "loading file added_tokens.json from cache at /Users/sampastoriza/.cache/huggingface/hub/models--finiteautomata--bertweet-base-emotion-analysis/snapshots/64046df9cc41eab40e1ecde7d2b7fb42b971be5b/added_tokens.json\n",
      "loading file special_tokens_map.json from cache at /Users/sampastoriza/.cache/huggingface/hub/models--finiteautomata--bertweet-base-emotion-analysis/snapshots/64046df9cc41eab40e1ecde7d2b7fb42b971be5b/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /Users/sampastoriza/.cache/huggingface/hub/models--finiteautomata--bertweet-base-emotion-analysis/snapshots/64046df9cc41eab40e1ecde7d2b7fb42b971be5b/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /Users/sampastoriza/.cache/huggingface/hub/models--finiteautomata--bertweet-base-emotion-analysis/snapshots/64046df9cc41eab40e1ecde7d2b7fb42b971be5b/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"finiteautomata/bertweet-base-emotion-analysis\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"others\",\n",
      "    \"1\": \"joy\",\n",
      "    \"2\": \"sadness\",\n",
      "    \"3\": \"anger\",\n",
      "    \"4\": \"surprise\",\n",
      "    \"5\": \"disgust\",\n",
      "    \"6\": \"fear\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 3,\n",
      "    \"disgust\": 5,\n",
      "    \"fear\": 6,\n",
      "    \"joy\": 1,\n",
      "    \"others\": 0,\n",
      "    \"sadness\": 2,\n",
      "    \"surprise\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"tokenizer_class\": \"BertweetTokenizer\",\n",
      "  \"transformers_version\": \"4.23.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 64001\n",
      "}\n",
      "\n",
      "Adding <mask> to the vocabulary\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc66719b17ac405a8bd152d99e378c7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/980 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /Users/sampastoriza/.cache/huggingface/hub/models--pysentimiento--bertweet-hate-speech/snapshots/8913cd6a2515f3e033c3b097f68d3bfb41079c54/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"pysentimiento/bertweet-hate-speech\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"hateful\",\n",
      "    \"1\": \"targeted\",\n",
      "    \"2\": \"aggressive\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"aggressive\": 2,\n",
      "    \"hateful\": 0,\n",
      "    \"targeted\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"multi_label_classification\",\n",
      "  \"tokenizer_class\": \"BertweetTokenizer\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.23.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 64001\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9a730973e0e4974a4369b263ae81bb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/540M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file pytorch_model.bin from cache at /Users/sampastoriza/.cache/huggingface/hub/models--pysentimiento--bertweet-hate-speech/snapshots/8913cd6a2515f3e033c3b097f68d3bfb41079c54/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at pysentimiento/bertweet-hate-speech.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f69dba4de124694a200728d5995caf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/335 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43ba9670d018470e9f5f1f25da9d743d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/843k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "689d56d699984971bf1078963ffe4ece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe027e75dcd14050b3896053b2e5bf1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/17.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5bd6030658d4a34ba3932ba77463bb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.txt from cache at /Users/sampastoriza/.cache/huggingface/hub/models--pysentimiento--bertweet-hate-speech/snapshots/8913cd6a2515f3e033c3b097f68d3bfb41079c54/vocab.txt\n",
      "loading file bpe.codes from cache at /Users/sampastoriza/.cache/huggingface/hub/models--pysentimiento--bertweet-hate-speech/snapshots/8913cd6a2515f3e033c3b097f68d3bfb41079c54/bpe.codes\n",
      "loading file added_tokens.json from cache at /Users/sampastoriza/.cache/huggingface/hub/models--pysentimiento--bertweet-hate-speech/snapshots/8913cd6a2515f3e033c3b097f68d3bfb41079c54/added_tokens.json\n",
      "loading file special_tokens_map.json from cache at /Users/sampastoriza/.cache/huggingface/hub/models--pysentimiento--bertweet-hate-speech/snapshots/8913cd6a2515f3e033c3b097f68d3bfb41079c54/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /Users/sampastoriza/.cache/huggingface/hub/models--pysentimiento--bertweet-hate-speech/snapshots/8913cd6a2515f3e033c3b097f68d3bfb41079c54/tokenizer_config.json\n",
      "Adding <mask> to the vocabulary\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "### THIS TAKES A LONG TIME TO RUN \n",
    "\n",
    "from pysentimiento import create_analyzer\n",
    "\n",
    "# loading transformer sentiment model \n",
    "analyzer = create_analyzer(task=\"sentiment\", lang=\"en\")\n",
    "\n",
    "# loading transformer emotion model \n",
    "emotion_analyzer = create_analyzer(task=\"emotion\", lang=\"en\")\n",
    "\n",
    "# loading transformer hate speech model \n",
    "hate_speech_analyzer = create_analyzer(task=\"hate_speech\", lang=\"en\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting output from transformer sentiment model \n",
    "def enhanced_sentiment_scores(text):\n",
    "    score = analyzer.predict(text) \n",
    "    return score\n",
    "\n",
    "# getting output from transformer emotion model \n",
    "def emotion_scores(text):\n",
    "    score = emotion_analyzer.predict(text) \n",
    "    return score\n",
    "\n",
    "# getting output from transformer hate speech model \n",
    "def hate_speech_scores(text):\n",
    "    score = hate_speech_analyzer.predict(text) \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### THIS TAKES A LONG TIME TO RUN \n",
    "\n",
    "data['pysentimiento_sentiment'] = data['text'].apply(enhanced_sentiment_scores)\n",
    "\n",
    "data['pysentimiento_emotion'] = data['text'].apply(emotion_scores)\n",
    "\n",
    "data['pysentimiento_hate'] = data['text'].apply(hate_speech_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sentiment_output'] = data['pysentimiento_sentiment'].apply(lambda x: x.probas)\n",
    "data['sentiment_probs'] = data['pysentimiento_sentiment'].apply(lambda x: x.output)\n",
    "\n",
    "data['emotion_output'] = data['pysentimiento_emotion'].apply(lambda x: x.probas)\n",
    "data['_probs'] = data['pysentimiento_emotion'].apply(lambda x: x.output)\n",
    "\n",
    "data['hate_output'] = data['pysentimiento_hate'].apply(lambda x: x.probas)\n",
    "data['hate_probs'] = data['pysentimiento_hate'].apply(lambda x: x.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['pysentimiento_sentiment', 'pysentimiento_emotion', 'pysentimiento_hate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>user_mention_ids</th>\n",
       "      <th>user_mention_screen_names</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>in_reply_to_screen_name</th>\n",
       "      <th>...</th>\n",
       "      <th>topic_y</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>sentiment_bin</th>\n",
       "      <th>sentiment_output</th>\n",
       "      <th>sentiment_probs</th>\n",
       "      <th>emotion_output</th>\n",
       "      <th>_probs</th>\n",
       "      <th>hate_output</th>\n",
       "      <th>hate_probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-18 00:00:00</td>\n",
       "      <td>Sharp words on guns in Shane Hazel to Stacey A...</td>\n",
       "      <td>['gagovdebate']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>abrams</td>\n",
       "      <td>Sharp words on guns in Shane Hazel to Stacey A...</td>\n",
       "      <td>0.3818</td>\n",
       "      <td>positive</td>\n",
       "      <td>{'NEG': 0.8212317228317261, 'NEU': 0.174511402...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>{'others': 0.207327738404274, 'joy': 0.0029463...</td>\n",
       "      <td>disgust</td>\n",
       "      <td>{'hateful': 0.006341646425426006, 'targeted': ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-10-18 00:00:01</td>\n",
       "      <td>Stacey Abrams won tonight. She kept to the fac...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>abrams</td>\n",
       "      <td>Stacey Abrams won tonight She kept to the fact...</td>\n",
       "      <td>0.7351</td>\n",
       "      <td>positive</td>\n",
       "      <td>{'NEG': 0.016344917938113213, 'NEU': 0.3160411...</td>\n",
       "      <td>POS</td>\n",
       "      <td>{'others': 0.9740464687347412, 'joy': 0.014125...</td>\n",
       "      <td>others</td>\n",
       "      <td>{'hateful': 0.01308343093842268, 'targeted': 0...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-10-18 00:00:01</td>\n",
       "      <td>Why did Joe Rogan send his little brother, Sha...</td>\n",
       "      <td>['GAGovDebate']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>abrams</td>\n",
       "      <td>Why did Joe Rogan send his little brother Shan...</td>\n",
       "      <td>-0.2500</td>\n",
       "      <td>negative</td>\n",
       "      <td>{'NEG': 0.39890310168266296, 'NEU': 0.59211242...</td>\n",
       "      <td>NEU</td>\n",
       "      <td>{'others': 0.05201367661356926, 'joy': 0.00170...</td>\n",
       "      <td>disgust</td>\n",
       "      <td>{'hateful': 0.07990611344575882, 'targeted': 0...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2022-10-18 00:00:08</td>\n",
       "      <td>Viral handbag designer and EBONY Power100 Styl...</td>\n",
       "      <td>['StaceyAbrams', 'BrandonBlackwood', 'EBONYMag']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>abrams</td>\n",
       "      <td>Viral handbag designer and EBONY Powernumber S...</td>\n",
       "      <td>0.7184</td>\n",
       "      <td>positive</td>\n",
       "      <td>{'NEG': 0.0015979005256667733, 'NEU': 0.925578...</td>\n",
       "      <td>NEU</td>\n",
       "      <td>{'others': 0.9076645970344543, 'joy': 0.080004...</td>\n",
       "      <td>others</td>\n",
       "      <td>{'hateful': 0.0050714933313429356, 'targeted':...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2022-10-18 00:00:11</td>\n",
       "      <td>THE MOST DANGEROUS THING FACING GEORGIA IS 4 M...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>212</td>\n",
       "      <td>528</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>kemp</td>\n",
       "      <td>THE MOST DANGEROUS THING FACING GEORGIA IS num...</td>\n",
       "      <td>0.1776</td>\n",
       "      <td>positive</td>\n",
       "      <td>{'NEG': 0.9775214195251465, 'NEU': 0.018825154...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>{'others': 0.007493030279874802, 'joy': 0.0018...</td>\n",
       "      <td>fear</td>\n",
       "      <td>{'hateful': 0.009111088700592518, 'targeted': ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           created_at  \\\n",
       "0           0  2022-10-18 00:00:00   \n",
       "1           1  2022-10-18 00:00:01   \n",
       "2           2  2022-10-18 00:00:01   \n",
       "3           3  2022-10-18 00:00:08   \n",
       "4           4  2022-10-18 00:00:11   \n",
       "\n",
       "                                                text  \\\n",
       "0  Sharp words on guns in Shane Hazel to Stacey A...   \n",
       "1  Stacey Abrams won tonight. She kept to the fac...   \n",
       "2  Why did Joe Rogan send his little brother, Sha...   \n",
       "3  Viral handbag designer and EBONY Power100 Styl...   \n",
       "4  THE MOST DANGEROUS THING FACING GEORGIA IS 4 M...   \n",
       "\n",
       "                                           hashtags user_mention_ids  \\\n",
       "0                                   ['gagovdebate']               []   \n",
       "1                                                []               []   \n",
       "2                                   ['GAGovDebate']               []   \n",
       "3  ['StaceyAbrams', 'BrandonBlackwood', 'EBONYMag']               []   \n",
       "4                                                []               []   \n",
       "\n",
       "  user_mention_screen_names  retweet_count  favorite_count  \\\n",
       "0                        []              5              24   \n",
       "1                        []              0               6   \n",
       "2                        []              0               5   \n",
       "3                        []              1               8   \n",
       "4                        []            212             528   \n",
       "\n",
       "   in_reply_to_user_id in_reply_to_screen_name  ... topic_y  \\\n",
       "0                  NaN                     NaN  ...  abrams   \n",
       "1                  NaN                     NaN  ...  abrams   \n",
       "2                  NaN                     NaN  ...  abrams   \n",
       "3                  NaN                     NaN  ...  abrams   \n",
       "4                  NaN                     NaN  ...    kemp   \n",
       "\n",
       "                                        cleaned_text  sentiment_score  \\\n",
       "0  Sharp words on guns in Shane Hazel to Stacey A...           0.3818   \n",
       "1  Stacey Abrams won tonight She kept to the fact...           0.7351   \n",
       "2  Why did Joe Rogan send his little brother Shan...          -0.2500   \n",
       "3  Viral handbag designer and EBONY Powernumber S...           0.7184   \n",
       "4  THE MOST DANGEROUS THING FACING GEORGIA IS num...           0.1776   \n",
       "\n",
       "  sentiment_bin                                   sentiment_output  \\\n",
       "0      positive  {'NEG': 0.8212317228317261, 'NEU': 0.174511402...   \n",
       "1      positive  {'NEG': 0.016344917938113213, 'NEU': 0.3160411...   \n",
       "2      negative  {'NEG': 0.39890310168266296, 'NEU': 0.59211242...   \n",
       "3      positive  {'NEG': 0.0015979005256667733, 'NEU': 0.925578...   \n",
       "4      positive  {'NEG': 0.9775214195251465, 'NEU': 0.018825154...   \n",
       "\n",
       "  sentiment_probs                                     emotion_output   _probs  \\\n",
       "0             NEG  {'others': 0.207327738404274, 'joy': 0.0029463...  disgust   \n",
       "1             POS  {'others': 0.9740464687347412, 'joy': 0.014125...   others   \n",
       "2             NEU  {'others': 0.05201367661356926, 'joy': 0.00170...  disgust   \n",
       "3             NEU  {'others': 0.9076645970344543, 'joy': 0.080004...   others   \n",
       "4             NEG  {'others': 0.007493030279874802, 'joy': 0.0018...     fear   \n",
       "\n",
       "                                         hate_output  hate_probs  \n",
       "0  {'hateful': 0.006341646425426006, 'targeted': ...          []  \n",
       "1  {'hateful': 0.01308343093842268, 'targeted': 0...          []  \n",
       "2  {'hateful': 0.07990611344575882, 'targeted': 0...          []  \n",
       "3  {'hateful': 0.0050714933313429356, 'targeted':...          []  \n",
       "4  {'hateful': 0.009111088700592518, 'targeted': ...          []  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv file\n",
    "data.to_csv('data_with_sentiment.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8869554c2df41533e161d2a767d82e0a2352f547309fff6a28adf765944d6958"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
