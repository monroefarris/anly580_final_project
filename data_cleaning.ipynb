{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation for NLP Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>user_mention_ids</th>\n",
       "      <th>user_mention_screen_names</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>in_reply_to_screen_name</th>\n",
       "      <th>...</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_friends_count</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>user_favourites_count</th>\n",
       "      <th>user_verfied</th>\n",
       "      <th>user_statuses_count</th>\n",
       "      <th>topic_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-18 00:00:00</td>\n",
       "      <td>Sharp words on guns in Shane Hazel to Stacey A...</td>\n",
       "      <td>['gagovdebate']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>25282846</td>\n",
       "      <td>SimonesNews</td>\n",
       "      <td>Simone Sebastian</td>\n",
       "      <td>Washington DC</td>\n",
       "      <td>3110</td>\n",
       "      <td>5830</td>\n",
       "      <td>1445</td>\n",
       "      <td>True</td>\n",
       "      <td>4400</td>\n",
       "      <td>abrams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-10-18 00:00:01</td>\n",
       "      <td>Stacey Abrams won tonight. She kept to the fac...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1312393604439183361</td>\n",
       "      <td>nching0</td>\n",
       "      <td>Thee Lost Edges of Candace ðŸª¥</td>\n",
       "      <td>34.2073Â° N, 84.1402Â° W</td>\n",
       "      <td>922</td>\n",
       "      <td>752</td>\n",
       "      <td>101529</td>\n",
       "      <td>False</td>\n",
       "      <td>61963</td>\n",
       "      <td>abrams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           created_at  \\\n",
       "0           0  2022-10-18 00:00:00   \n",
       "1           1  2022-10-18 00:00:01   \n",
       "\n",
       "                                                text         hashtags  \\\n",
       "0  Sharp words on guns in Shane Hazel to Stacey A...  ['gagovdebate']   \n",
       "1  Stacey Abrams won tonight. She kept to the fac...               []   \n",
       "\n",
       "  user_mention_ids user_mention_screen_names  retweet_count  favorite_count  \\\n",
       "0               []                        []              5              24   \n",
       "1               []                        []              0               6   \n",
       "\n",
       "   in_reply_to_user_id in_reply_to_screen_name  ...              user_id  \\\n",
       "0                  NaN                     NaN  ...             25282846   \n",
       "1                  NaN                     NaN  ...  1312393604439183361   \n",
       "\n",
       "  user_screen_name                     user_name           user_location  \\\n",
       "0      SimonesNews              Simone Sebastian           Washington DC   \n",
       "1          nching0  Thee Lost Edges of Candace ðŸª¥  34.2073Â° N, 84.1402Â° W   \n",
       "\n",
       "  user_friends_count user_followers_count  user_favourites_count  \\\n",
       "0               3110                 5830                   1445   \n",
       "1                922                  752                 101529   \n",
       "\n",
       "   user_verfied  user_statuses_count  topic_y  \n",
       "0          True                 4400   abrams  \n",
       "1         False                61963   abrams  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in data \n",
    "data = pd.read_csv('./Data/all_data.csv')\n",
    "\n",
    "# Understand output of data\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Data Quality Checks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows with No Text Data: 0\n"
     ]
    }
   ],
   "source": [
    "# Check if there are any rows where with no text data\n",
    "print('Number of Rows with No Text Data:', data['text'].isnull().values.any().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tweets: 51336\n"
     ]
    }
   ],
   "source": [
    "# Get number of Tweets in our corpus \n",
    "print('Number of Tweets:', len(data['text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the basic data quality check we see that every Tweet returned does contain text. With this information, we can now move onto the text cleaning and pre-processing stages. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now clean the text by removing excess punctuation, spaces, and special characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex statement for cleaning \n",
    "replace = [\n",
    "    (r\"(?<=\\d),(?=\\d)\", \"\"),        # Remove commas in numbers\n",
    "    (r\"\\d+\", \"number\"),             # Map digits to special token <numbr>\n",
    "    (r\"[\\t\\n\\r\\*\\.\\@\\,\\-\\/]\", \" \"), # Punctuation and other junk\n",
    "    (r\"\\s+\", \" \")                   # Stips extra whitespace\n",
    "]\n",
    "\n",
    "# looping through all Tweets and applying regex cleaning \n",
    "train_sentences = []\n",
    "for i, d in enumerate(data['text']):\n",
    "    for repl in replace:\n",
    "        d = re.sub(repl[0], repl[1], d)\n",
    "    train_sentences.append(d)\n",
    "\n",
    "# writing output of regex cleaning to df column \n",
    "data['cleaned_text'] = train_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>user_mention_ids</th>\n",
       "      <th>user_mention_screen_names</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>in_reply_to_screen_name</th>\n",
       "      <th>geo</th>\n",
       "      <th>...</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_friends_count</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>user_favourites_count</th>\n",
       "      <th>user_verfied</th>\n",
       "      <th>user_statuses_count</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-11-03 13:23:56</td>\n",
       "      <td>I know these truths. Stacey Abrams will lose t...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1187835922118787073, 948223698649124870]</td>\n",
       "      <td>['lavern_spicer', 'raytoutofer']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.187836e+18</td>\n",
       "      <td>lavern_spicer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1541786385899819009</td>\n",
       "      <td>larrymondello63</td>\n",
       "      <td>Maxwell Smart 86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89</td>\n",
       "      <td>8</td>\n",
       "      <td>277</td>\n",
       "      <td>False</td>\n",
       "      <td>476</td>\n",
       "      <td>I know these truths Stacey Abrams will lose th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-11-03 13:23:45</td>\n",
       "      <td>Sort of like Stacey Abrams is still governor o...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[91882544]</td>\n",
       "      <td>['DineshDSouza']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.188254e+07</td>\n",
       "      <td>DineshDSouza</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1572885397285257216</td>\n",
       "      <td>KevinFodor2</td>\n",
       "      <td>Kevin Fodor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>717</td>\n",
       "      <td>100</td>\n",
       "      <td>1653</td>\n",
       "      <td>False</td>\n",
       "      <td>1079</td>\n",
       "      <td>Sort of like Stacey Abrams is still governor o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            created_at                                               text  \\\n",
       "0  2022-11-03 13:23:56  I know these truths. Stacey Abrams will lose t...   \n",
       "1  2022-11-03 13:23:45  Sort of like Stacey Abrams is still governor o...   \n",
       "\n",
       "  hashtags                           user_mention_ids  \\\n",
       "0       []  [1187835922118787073, 948223698649124870]   \n",
       "1       []                                 [91882544]   \n",
       "\n",
       "          user_mention_screen_names  retweet_count  favorite_count  \\\n",
       "0  ['lavern_spicer', 'raytoutofer']              0               0   \n",
       "1                  ['DineshDSouza']              0               0   \n",
       "\n",
       "   in_reply_to_user_id in_reply_to_screen_name  geo  ...              user_id  \\\n",
       "0         1.187836e+18           lavern_spicer  NaN  ...  1541786385899819009   \n",
       "1         9.188254e+07            DineshDSouza  NaN  ...  1572885397285257216   \n",
       "\n",
       "   user_screen_name         user_name user_location user_friends_count  \\\n",
       "0   larrymondello63  Maxwell Smart 86           NaN                 89   \n",
       "1       KevinFodor2       Kevin Fodor           NaN                717   \n",
       "\n",
       "   user_followers_count  user_favourites_count  user_verfied  \\\n",
       "0                     8                    277         False   \n",
       "1                   100                   1653         False   \n",
       "\n",
       "   user_statuses_count                                       cleaned_text  \n",
       "0                  476  I know these truths Stacey Abrams will lose th...  \n",
       "1                 1079  Sort of like Stacey Abrams is still governor o...  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a data frame with a new column `cleaned_text` that contains the cleaned version of each Tweet. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Cleaned Tweets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VADER Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading in sentiment libraries \n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading VADER sentiment model \n",
    "vader_sentiment = SentimentIntensityAnalyzer()\n",
    "\n",
    "# function that returns sentiment score for a series of text \n",
    "def vader_sentiment_scores(text):\n",
    "  score = vader_sentiment.polarity_scores(text)\n",
    "  \n",
    "  return score['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that bins sentiment into positive, negative, and neutral categories based on sentiment score \n",
    "def format_output(row):\n",
    "  polarity = \"neutral\"\n",
    "  if(row>= 0.05):\n",
    "    polarity = \"positive\"\n",
    "  elif(row<= -0.05):\n",
    "    polarity = \"negative\"\n",
    "\n",
    "  return polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting sentiment scores for corpus of text \n",
    "data['sentiment_score'] = data['text'].apply(vader_sentiment_scores)\n",
    "\n",
    "# getting sentiment bins for our data \n",
    "data['sentiment_bin'] = data['sentiment_score'].apply(format_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>user_mention_ids</th>\n",
       "      <th>user_mention_screen_names</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>in_reply_to_screen_name</th>\n",
       "      <th>geo</th>\n",
       "      <th>...</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_friends_count</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>user_favourites_count</th>\n",
       "      <th>user_verfied</th>\n",
       "      <th>user_statuses_count</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>sentiment_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-11-03 13:23:56</td>\n",
       "      <td>I know these truths. Stacey Abrams will lose t...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1187835922118787073, 948223698649124870]</td>\n",
       "      <td>['lavern_spicer', 'raytoutofer']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.187836e+18</td>\n",
       "      <td>lavern_spicer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Maxwell Smart 86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89</td>\n",
       "      <td>8</td>\n",
       "      <td>277</td>\n",
       "      <td>False</td>\n",
       "      <td>476</td>\n",
       "      <td>I know these truths Stacey Abrams will lose th...</td>\n",
       "      <td>0.6486</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-11-03 13:23:45</td>\n",
       "      <td>Sort of like Stacey Abrams is still governor o...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[91882544]</td>\n",
       "      <td>['DineshDSouza']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.188254e+07</td>\n",
       "      <td>DineshDSouza</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Kevin Fodor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>717</td>\n",
       "      <td>100</td>\n",
       "      <td>1653</td>\n",
       "      <td>False</td>\n",
       "      <td>1079</td>\n",
       "      <td>Sort of like Stacey Abrams is still governor o...</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-11-03 13:23:42</td>\n",
       "      <td>The Gargantuan Fundraising of Beto O'Rourke an...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Jim Geraghty</td>\n",
       "      <td>Authenticity Woods, Virginia.</td>\n",
       "      <td>1219</td>\n",
       "      <td>106991</td>\n",
       "      <td>16477</td>\n",
       "      <td>True</td>\n",
       "      <td>118131</td>\n",
       "      <td>The Gargantuan Fundraising of Beto O'Rourke an...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            created_at                                               text  \\\n",
       "0  2022-11-03 13:23:56  I know these truths. Stacey Abrams will lose t...   \n",
       "1  2022-11-03 13:23:45  Sort of like Stacey Abrams is still governor o...   \n",
       "2  2022-11-03 13:23:42  The Gargantuan Fundraising of Beto O'Rourke an...   \n",
       "\n",
       "  hashtags                           user_mention_ids  \\\n",
       "0       []  [1187835922118787073, 948223698649124870]   \n",
       "1       []                                 [91882544]   \n",
       "2       []                                         []   \n",
       "\n",
       "          user_mention_screen_names  retweet_count  favorite_count  \\\n",
       "0  ['lavern_spicer', 'raytoutofer']              0               0   \n",
       "1                  ['DineshDSouza']              0               0   \n",
       "2                                []              0               1   \n",
       "\n",
       "   in_reply_to_user_id in_reply_to_screen_name  geo  ...         user_name  \\\n",
       "0         1.187836e+18           lavern_spicer  NaN  ...  Maxwell Smart 86   \n",
       "1         9.188254e+07            DineshDSouza  NaN  ...       Kevin Fodor   \n",
       "2                  NaN                     NaN  NaN  ...      Jim Geraghty   \n",
       "\n",
       "                   user_location user_friends_count user_followers_count  \\\n",
       "0                            NaN                 89                    8   \n",
       "1                            NaN                717                  100   \n",
       "2  Authenticity Woods, Virginia.               1219               106991   \n",
       "\n",
       "  user_favourites_count  user_verfied  user_statuses_count  \\\n",
       "0                   277         False                  476   \n",
       "1                  1653         False                 1079   \n",
       "2                 16477          True               118131   \n",
       "\n",
       "                                        cleaned_text  sentiment_score  \\\n",
       "0  I know these truths Stacey Abrams will lose th...           0.6486   \n",
       "1  Sort of like Stacey Abrams is still governor o...           0.3612   \n",
       "2  The Gargantuan Fundraising of Beto O'Rourke an...           0.0000   \n",
       "\n",
       "   sentiment_bin  \n",
       "0       positive  \n",
       "1       positive  \n",
       "2        neutral  \n",
       "\n",
       "[3 rows x 23 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examining data frame with sentiment scores and bins\n",
    "data.head(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('anly_nn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c810761776810c6b6690fdd35fa5cf3a0b569b85a1082c5024439e21e3b34f97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
