{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation for NLP Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>user_mention_ids</th>\n",
       "      <th>user_mention_screen_names</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>in_reply_to_screen_name</th>\n",
       "      <th>...</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_friends_count</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>user_favourites_count</th>\n",
       "      <th>user_verfied</th>\n",
       "      <th>user_statuses_count</th>\n",
       "      <th>topic_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-18 00:00:00</td>\n",
       "      <td>Sharp words on guns in Shane Hazel to Stacey A...</td>\n",
       "      <td>['gagovdebate']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>25282846</td>\n",
       "      <td>SimonesNews</td>\n",
       "      <td>Simone Sebastian</td>\n",
       "      <td>Washington DC</td>\n",
       "      <td>3110</td>\n",
       "      <td>5830</td>\n",
       "      <td>1445</td>\n",
       "      <td>True</td>\n",
       "      <td>4400</td>\n",
       "      <td>abrams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-10-18 00:00:01</td>\n",
       "      <td>Stacey Abrams won tonight. She kept to the fac...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1312393604439183361</td>\n",
       "      <td>nching0</td>\n",
       "      <td>Thee Lost Edges of Candace ðŸª¥</td>\n",
       "      <td>34.2073Â° N, 84.1402Â° W</td>\n",
       "      <td>922</td>\n",
       "      <td>752</td>\n",
       "      <td>101529</td>\n",
       "      <td>False</td>\n",
       "      <td>61963</td>\n",
       "      <td>abrams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           created_at  \\\n",
       "0           0  2022-10-18 00:00:00   \n",
       "1           1  2022-10-18 00:00:01   \n",
       "\n",
       "                                                text         hashtags  \\\n",
       "0  Sharp words on guns in Shane Hazel to Stacey A...  ['gagovdebate']   \n",
       "1  Stacey Abrams won tonight. She kept to the fac...               []   \n",
       "\n",
       "  user_mention_ids user_mention_screen_names  retweet_count  favorite_count  \\\n",
       "0               []                        []              5              24   \n",
       "1               []                        []              0               6   \n",
       "\n",
       "   in_reply_to_user_id in_reply_to_screen_name  ...              user_id  \\\n",
       "0                  NaN                     NaN  ...             25282846   \n",
       "1                  NaN                     NaN  ...  1312393604439183361   \n",
       "\n",
       "  user_screen_name                     user_name           user_location  \\\n",
       "0      SimonesNews              Simone Sebastian           Washington DC   \n",
       "1          nching0  Thee Lost Edges of Candace ðŸª¥  34.2073Â° N, 84.1402Â° W   \n",
       "\n",
       "  user_friends_count user_followers_count  user_favourites_count  \\\n",
       "0               3110                 5830                   1445   \n",
       "1                922                  752                 101529   \n",
       "\n",
       "   user_verfied  user_statuses_count  topic_y  \n",
       "0          True                 4400   abrams  \n",
       "1         False                61963   abrams  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in data \n",
    "data = pd.read_csv('./Data/all_data.csv')\n",
    "\n",
    "# Understand output of data\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Data Quality Checks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows with No Text Data: 0\n"
     ]
    }
   ],
   "source": [
    "# Check if there are any rows where with no text data\n",
    "print('Number of Rows with No Text Data:', data['text'].isnull().values.any().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tweets: 51336\n"
     ]
    }
   ],
   "source": [
    "# Get number of Tweets in our corpus \n",
    "print('Number of Tweets:', len(data['text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the basic data quality check we see that every Tweet returned does contain text. With this information, we can now move onto the text cleaning and pre-processing stages. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now clean the text by removing excess punctuation, spaces, and special characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex statement for cleaning \n",
    "replace = [\n",
    "    (r\"(?<=\\d),(?=\\d)\", \"\"),        # Remove commas in numbers\n",
    "    (r\"\\d+\", \"number\"),             # Map digits to special token <numbr>\n",
    "    (r\"[\\t\\n\\r\\*\\.\\@\\,\\-\\/]\", \" \"), # Punctuation and other junk\n",
    "    (r\"\\s+\", \" \")                   # Stips extra whitespace\n",
    "]\n",
    "\n",
    "# looping through all Tweets and applying regex cleaning \n",
    "train_sentences = []\n",
    "for i, d in enumerate(data['text']):\n",
    "    for repl in replace:\n",
    "        d = re.sub(repl[0], repl[1], d)\n",
    "    train_sentences.append(d)\n",
    "\n",
    "# writing output of regex cleaning to df column \n",
    "data['cleaned_text'] = train_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>user_mention_ids</th>\n",
       "      <th>user_mention_screen_names</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>in_reply_to_screen_name</th>\n",
       "      <th>...</th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_friends_count</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>user_favourites_count</th>\n",
       "      <th>user_verfied</th>\n",
       "      <th>user_statuses_count</th>\n",
       "      <th>topic_y</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-18 00:00:00</td>\n",
       "      <td>Sharp words on guns in Shane Hazel to Stacey A...</td>\n",
       "      <td>['gagovdebate']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>SimonesNews</td>\n",
       "      <td>Simone Sebastian</td>\n",
       "      <td>Washington DC</td>\n",
       "      <td>3110</td>\n",
       "      <td>5830</td>\n",
       "      <td>1445</td>\n",
       "      <td>True</td>\n",
       "      <td>4400</td>\n",
       "      <td>abrams</td>\n",
       "      <td>Sharp words on guns in Shane Hazel to Stacey A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-10-18 00:00:01</td>\n",
       "      <td>Stacey Abrams won tonight. She kept to the fac...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>nching0</td>\n",
       "      <td>Thee Lost Edges of Candace ðŸª¥</td>\n",
       "      <td>34.2073Â° N, 84.1402Â° W</td>\n",
       "      <td>922</td>\n",
       "      <td>752</td>\n",
       "      <td>101529</td>\n",
       "      <td>False</td>\n",
       "      <td>61963</td>\n",
       "      <td>abrams</td>\n",
       "      <td>Stacey Abrams won tonight She kept to the fact...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           created_at  \\\n",
       "0           0  2022-10-18 00:00:00   \n",
       "1           1  2022-10-18 00:00:01   \n",
       "\n",
       "                                                text         hashtags  \\\n",
       "0  Sharp words on guns in Shane Hazel to Stacey A...  ['gagovdebate']   \n",
       "1  Stacey Abrams won tonight. She kept to the fac...               []   \n",
       "\n",
       "  user_mention_ids user_mention_screen_names  retweet_count  favorite_count  \\\n",
       "0               []                        []              5              24   \n",
       "1               []                        []              0               6   \n",
       "\n",
       "   in_reply_to_user_id in_reply_to_screen_name  ... user_screen_name  \\\n",
       "0                  NaN                     NaN  ...      SimonesNews   \n",
       "1                  NaN                     NaN  ...          nching0   \n",
       "\n",
       "                      user_name           user_location user_friends_count  \\\n",
       "0              Simone Sebastian           Washington DC               3110   \n",
       "1  Thee Lost Edges of Candace ðŸª¥  34.2073Â° N, 84.1402Â° W                922   \n",
       "\n",
       "  user_followers_count user_favourites_count  user_verfied  \\\n",
       "0                 5830                  1445          True   \n",
       "1                  752                101529         False   \n",
       "\n",
       "   user_statuses_count  topic_y  \\\n",
       "0                 4400   abrams   \n",
       "1                61963   abrams   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  Sharp words on guns in Shane Hazel to Stacey A...  \n",
       "1  Stacey Abrams won tonight She kept to the fact...  \n",
       "\n",
       "[2 rows x 23 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a data frame with a new column `cleaned_text` that contains the cleaned version of each Tweet. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Cleaned Tweets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VADER Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading in sentiment libraries \n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading VADER sentiment model \n",
    "vader_sentiment = SentimentIntensityAnalyzer()\n",
    "\n",
    "# function that returns sentiment score for a series of text \n",
    "def vader_sentiment_scores(text):\n",
    "  score = vader_sentiment.polarity_scores(text)\n",
    "  \n",
    "  return score['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that bins sentiment into positive, negative, and neutral categories based on sentiment score \n",
    "def format_output(row):\n",
    "  polarity = \"neutral\"\n",
    "  if(row>= 0.05):\n",
    "    polarity = \"positive\"\n",
    "  elif(row<= -0.05):\n",
    "    polarity = \"negative\"\n",
    "\n",
    "  return polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting sentiment scores for corpus of text \n",
    "data['sentiment_score'] = data['text'].apply(vader_sentiment_scores)\n",
    "\n",
    "# getting sentiment bins for our data \n",
    "data['sentiment_bin'] = data['sentiment_score'].apply(format_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>user_mention_ids</th>\n",
       "      <th>user_mention_screen_names</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>in_reply_to_screen_name</th>\n",
       "      <th>...</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_friends_count</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>user_favourites_count</th>\n",
       "      <th>user_verfied</th>\n",
       "      <th>user_statuses_count</th>\n",
       "      <th>topic_y</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>sentiment_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-18 00:00:00</td>\n",
       "      <td>Sharp words on guns in Shane Hazel to Stacey A...</td>\n",
       "      <td>['gagovdebate']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Washington DC</td>\n",
       "      <td>3110</td>\n",
       "      <td>5830</td>\n",
       "      <td>1445</td>\n",
       "      <td>True</td>\n",
       "      <td>4400</td>\n",
       "      <td>abrams</td>\n",
       "      <td>Sharp words on guns in Shane Hazel to Stacey A...</td>\n",
       "      <td>0.3818</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-10-18 00:00:01</td>\n",
       "      <td>Stacey Abrams won tonight. She kept to the fac...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>34.2073Â° N, 84.1402Â° W</td>\n",
       "      <td>922</td>\n",
       "      <td>752</td>\n",
       "      <td>101529</td>\n",
       "      <td>False</td>\n",
       "      <td>61963</td>\n",
       "      <td>abrams</td>\n",
       "      <td>Stacey Abrams won tonight She kept to the fact...</td>\n",
       "      <td>0.7351</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-10-18 00:00:01</td>\n",
       "      <td>Why did Joe Rogan send his little brother, Sha...</td>\n",
       "      <td>['GAGovDebate']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>17762</td>\n",
       "      <td>25727</td>\n",
       "      <td>82402</td>\n",
       "      <td>False</td>\n",
       "      <td>43808</td>\n",
       "      <td>abrams</td>\n",
       "      <td>Why did Joe Rogan send his little brother Shan...</td>\n",
       "      <td>-0.2500</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           created_at  \\\n",
       "0           0  2022-10-18 00:00:00   \n",
       "1           1  2022-10-18 00:00:01   \n",
       "2           2  2022-10-18 00:00:01   \n",
       "\n",
       "                                                text         hashtags  \\\n",
       "0  Sharp words on guns in Shane Hazel to Stacey A...  ['gagovdebate']   \n",
       "1  Stacey Abrams won tonight. She kept to the fac...               []   \n",
       "2  Why did Joe Rogan send his little brother, Sha...  ['GAGovDebate']   \n",
       "\n",
       "  user_mention_ids user_mention_screen_names  retweet_count  favorite_count  \\\n",
       "0               []                        []              5              24   \n",
       "1               []                        []              0               6   \n",
       "2               []                        []              0               5   \n",
       "\n",
       "   in_reply_to_user_id in_reply_to_screen_name  ...           user_location  \\\n",
       "0                  NaN                     NaN  ...           Washington DC   \n",
       "1                  NaN                     NaN  ...  34.2073Â° N, 84.1402Â° W   \n",
       "2                  NaN                     NaN  ...                 Seattle   \n",
       "\n",
       "  user_friends_count  user_followers_count user_favourites_count user_verfied  \\\n",
       "0               3110                  5830                  1445         True   \n",
       "1                922                   752                101529        False   \n",
       "2              17762                 25727                 82402        False   \n",
       "\n",
       "  user_statuses_count  topic_y  \\\n",
       "0                4400   abrams   \n",
       "1               61963   abrams   \n",
       "2               43808   abrams   \n",
       "\n",
       "                                        cleaned_text  sentiment_score  \\\n",
       "0  Sharp words on guns in Shane Hazel to Stacey A...           0.3818   \n",
       "1  Stacey Abrams won tonight She kept to the fact...           0.7351   \n",
       "2  Why did Joe Rogan send his little brother Shan...          -0.2500   \n",
       "\n",
       "   sentiment_bin  \n",
       "0       positive  \n",
       "1       positive  \n",
       "2       negative  \n",
       "\n",
       "[3 rows x 25 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examining data frame with sentiment scores and bins\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pysentimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b85b5154b1c244829f2604bc92b92060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/999 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /Users/monroefarris/.cache/huggingface/hub/models--finiteautomata--bertweet-base-emotion-analysis/snapshots/64046df9cc41eab40e1ecde7d2b7fb42b971be5b/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"finiteautomata/bertweet-base-emotion-analysis\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"others\",\n",
      "    \"1\": \"joy\",\n",
      "    \"2\": \"sadness\",\n",
      "    \"3\": \"anger\",\n",
      "    \"4\": \"surprise\",\n",
      "    \"5\": \"disgust\",\n",
      "    \"6\": \"fear\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 3,\n",
      "    \"disgust\": 5,\n",
      "    \"fear\": 6,\n",
      "    \"joy\": 1,\n",
      "    \"others\": 0,\n",
      "    \"sadness\": 2,\n",
      "    \"surprise\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"tokenizer_class\": \"BertweetTokenizer\",\n",
      "  \"transformers_version\": \"4.23.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 64001\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1d267adf20140138b128e0ec3c5d20f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/540M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-7758afd823ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# analyzer = create_analyzer(task=\"sentiment\", lang=\"es\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0memotion_analyzer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_analyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"emotion\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"en\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pysentimiento/analyzer.py\u001b[0m in \u001b[0;36mcreate_analyzer\u001b[0;34m(task, lang, model_name, preprocessing_args, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0mpreprocessing_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lang\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0manalyzer_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_model_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocessing_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pysentimiento/analyzer.py\u001b[0m in \u001b[0;36mfrom_model_name\u001b[0;34m(cls, model_name, task, preprocessing_args, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mModel\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \"\"\"\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocessing_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    464\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m             )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2087\u001b[0m                         \u001b[0m_commit_hash\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcommit_hash\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2088\u001b[0m                     )\n\u001b[0;32m-> 2089\u001b[0;31m                     \u001b[0mresolved_archive_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcached_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcached_file_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2091\u001b[0m                     \u001b[0;31m# Since we set _raise_exceptions_for_missing_entries=False, we don't get an exception but a None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    410\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, use_auth_token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[1;32m   1224\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"downloading %s to %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1226\u001b[0;31m             http_get(\n\u001b[0m\u001b[1;32m   1227\u001b[0m                 \u001b[0murl_to_download\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m                 \u001b[0mtemp_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers, timeout, max_retries)\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetEffectiveLevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOTSET\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m     )\n\u001b[0;32m--> 490\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# filter out keep-alive new chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0mprogress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'stream'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_fp_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m                 \u001b[0mcache_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfp_closed\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m                 if (\n\u001b[1;32m    520\u001b[0m                     \u001b[0mamt\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m             \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1239\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1241\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### THIS TAKES A LONG TIME TO RUN \n",
    "\n",
    "from pysentimiento import create_analyzer\n",
    "\n",
    "# loading transformer sentiment model \n",
    "analyzer = create_analyzer(task=\"sentiment\", lang=\"en\")\n",
    "\n",
    "# loading transformer emotion model \n",
    "emotion_analyzer = create_analyzer(task=\"emotion\", lang=\"en\")\n",
    "\n",
    "# loading transformer hate speech model \n",
    "hate_speech_analyzer = create_analyzer(task=\"hate_speech\", lang=\"en\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting output from transformer sentiment model \n",
    "def enhanced_sentiment_scores(text):\n",
    "    score = analyzer.predict(text) \n",
    "    return score\n",
    "\n",
    "# getting output from transformer emotion model \n",
    "def emotion_scores(text):\n",
    "    score = emotion_analyzer.predict(text) \n",
    "    return score\n",
    "\n",
    "# getting output from transformer hate speech model \n",
    "def hate_speech_scores(text):\n",
    "    score = hate_speech_analyzer.predict(text) \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### THIS TAKES A LONG TIME TO RUN \n",
    "\n",
    "data['pysentimiento_sentiment'] = data['text'].apply(enhanced_sentiment_scores)\n",
    "\n",
    "data['pysentimiento_emotion'] = data['text'].apply(emotion_scores)\n",
    "\n",
    "data['pysentimiento_hate'] = data['text'].apply(hate_speech_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>user_mention_ids</th>\n",
       "      <th>user_mention_screen_names</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>in_reply_to_screen_name</th>\n",
       "      <th>...</th>\n",
       "      <th>user_friends_count</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>user_favourites_count</th>\n",
       "      <th>user_verfied</th>\n",
       "      <th>user_statuses_count</th>\n",
       "      <th>topic_y</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>sentiment_bin</th>\n",
       "      <th>pysentimiento_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-18 00:00:00</td>\n",
       "      <td>Sharp words on guns in Shane Hazel to Stacey A...</td>\n",
       "      <td>['gagovdebate']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3110</td>\n",
       "      <td>5830</td>\n",
       "      <td>1445</td>\n",
       "      <td>True</td>\n",
       "      <td>4400</td>\n",
       "      <td>abrams</td>\n",
       "      <td>Sharp words on guns in Shane Hazel to Stacey A...</td>\n",
       "      <td>0.3818</td>\n",
       "      <td>positive</td>\n",
       "      <td>AnalyzerOutput(output=NEU, probas={NEU: 0.851,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-10-18 00:00:01</td>\n",
       "      <td>Stacey Abrams won tonight. She kept to the fac...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>922</td>\n",
       "      <td>752</td>\n",
       "      <td>101529</td>\n",
       "      <td>False</td>\n",
       "      <td>61963</td>\n",
       "      <td>abrams</td>\n",
       "      <td>Stacey Abrams won tonight She kept to the fact...</td>\n",
       "      <td>0.7351</td>\n",
       "      <td>positive</td>\n",
       "      <td>AnalyzerOutput(output=NEU, probas={NEU: 0.675,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-10-18 00:00:01</td>\n",
       "      <td>Why did Joe Rogan send his little brother, Sha...</td>\n",
       "      <td>['GAGovDebate']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>17762</td>\n",
       "      <td>25727</td>\n",
       "      <td>82402</td>\n",
       "      <td>False</td>\n",
       "      <td>43808</td>\n",
       "      <td>abrams</td>\n",
       "      <td>Why did Joe Rogan send his little brother Shan...</td>\n",
       "      <td>-0.2500</td>\n",
       "      <td>negative</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.637,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2022-10-18 00:00:08</td>\n",
       "      <td>Viral handbag designer and EBONY Power100 Styl...</td>\n",
       "      <td>['StaceyAbrams', 'BrandonBlackwood', 'EBONYMag']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2334</td>\n",
       "      <td>445954</td>\n",
       "      <td>4403</td>\n",
       "      <td>True</td>\n",
       "      <td>91289</td>\n",
       "      <td>abrams</td>\n",
       "      <td>Viral handbag designer and EBONY Powernumber S...</td>\n",
       "      <td>0.7184</td>\n",
       "      <td>positive</td>\n",
       "      <td>AnalyzerOutput(output=NEU, probas={NEU: 0.793,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2022-10-18 00:00:11</td>\n",
       "      <td>THE MOST DANGEROUS THING FACING GEORGIA IS 4 M...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>212</td>\n",
       "      <td>528</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1990</td>\n",
       "      <td>9076</td>\n",
       "      <td>42697</td>\n",
       "      <td>False</td>\n",
       "      <td>9657</td>\n",
       "      <td>kemp</td>\n",
       "      <td>THE MOST DANGEROUS THING FACING GEORGIA IS num...</td>\n",
       "      <td>0.1776</td>\n",
       "      <td>positive</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.943,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           created_at  \\\n",
       "0           0  2022-10-18 00:00:00   \n",
       "1           1  2022-10-18 00:00:01   \n",
       "2           2  2022-10-18 00:00:01   \n",
       "3           3  2022-10-18 00:00:08   \n",
       "4           4  2022-10-18 00:00:11   \n",
       "\n",
       "                                                text  \\\n",
       "0  Sharp words on guns in Shane Hazel to Stacey A...   \n",
       "1  Stacey Abrams won tonight. She kept to the fac...   \n",
       "2  Why did Joe Rogan send his little brother, Sha...   \n",
       "3  Viral handbag designer and EBONY Power100 Styl...   \n",
       "4  THE MOST DANGEROUS THING FACING GEORGIA IS 4 M...   \n",
       "\n",
       "                                           hashtags user_mention_ids  \\\n",
       "0                                   ['gagovdebate']               []   \n",
       "1                                                []               []   \n",
       "2                                   ['GAGovDebate']               []   \n",
       "3  ['StaceyAbrams', 'BrandonBlackwood', 'EBONYMag']               []   \n",
       "4                                                []               []   \n",
       "\n",
       "  user_mention_screen_names  retweet_count  favorite_count  \\\n",
       "0                        []              5              24   \n",
       "1                        []              0               6   \n",
       "2                        []              0               5   \n",
       "3                        []              1               8   \n",
       "4                        []            212             528   \n",
       "\n",
       "   in_reply_to_user_id in_reply_to_screen_name  ... user_friends_count  \\\n",
       "0                  NaN                     NaN  ...               3110   \n",
       "1                  NaN                     NaN  ...                922   \n",
       "2                  NaN                     NaN  ...              17762   \n",
       "3                  NaN                     NaN  ...               2334   \n",
       "4                  NaN                     NaN  ...               1990   \n",
       "\n",
       "  user_followers_count  user_favourites_count user_verfied  \\\n",
       "0                 5830                   1445         True   \n",
       "1                  752                 101529        False   \n",
       "2                25727                  82402        False   \n",
       "3               445954                   4403         True   \n",
       "4                 9076                  42697        False   \n",
       "\n",
       "  user_statuses_count topic_y  \\\n",
       "0                4400  abrams   \n",
       "1               61963  abrams   \n",
       "2               43808  abrams   \n",
       "3               91289  abrams   \n",
       "4                9657    kemp   \n",
       "\n",
       "                                        cleaned_text  sentiment_score  \\\n",
       "0  Sharp words on guns in Shane Hazel to Stacey A...           0.3818   \n",
       "1  Stacey Abrams won tonight She kept to the fact...           0.7351   \n",
       "2  Why did Joe Rogan send his little brother Shan...          -0.2500   \n",
       "3  Viral handbag designer and EBONY Powernumber S...           0.7184   \n",
       "4  THE MOST DANGEROUS THING FACING GEORGIA IS num...           0.1776   \n",
       "\n",
       "   sentiment_bin                               pysentimiento_output  \n",
       "0       positive  AnalyzerOutput(output=NEU, probas={NEU: 0.851,...  \n",
       "1       positive  AnalyzerOutput(output=NEU, probas={NEU: 0.675,...  \n",
       "2       negative  AnalyzerOutput(output=NEG, probas={NEG: 0.637,...  \n",
       "3       positive  AnalyzerOutput(output=NEU, probas={NEU: 0.793,...  \n",
       "4       positive  AnalyzerOutput(output=NEG, probas={NEG: 0.943,...  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aa3086612d71023ea6bd20cc6c5bbcf1cbba35b1e4a01dc87ce94ea3ec71eb10"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c810761776810c6b6690fdd35fa5cf3a0b569b85a1082c5024439e21e3b34f97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
